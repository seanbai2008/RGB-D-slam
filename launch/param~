Param: OdomFovis/FeatureWindowSize = "9"                   [The size of the n x n image patch surrounding each feature, used for keypoint matching.]
Param: OdomFovis/InlierMaxReprojectionError = "1.5"        [The maximum image-space reprojection error (in pixels) a feature match is allowed to have and still be considered an inlier in the set of features used for motion estimation.]
Param: OdomFovis/MaxKeypointsPerBucket = "25"              []
Param: OdomFovis/MaxMeanReprojectionError = "10.0"         [Maximum mean reprojection error over the inlier feature matches for the motion estimate to be considered valid.]
Param: OdomFovis/MaxPyramidLevel = "3"                     [The maximum Gaussian pyramid level to process the image at. Pyramid level 1 corresponds to the original image.]
Param: OdomFovis/MinFeaturesForEstimate = "10"             [Minimum number of features in the inlier set for the motion estimate to be considered valid.]
Param: OdomFovis/MinPyramidLevel = "0"                     [The minimum pyramid level.]
Param: OdomFovis/StereoMaxDisparity = "128"                []
Param: OdomFovis/StereoMaxDistEpipolarLine = "1.5"         []
Param: OdomFovis/StereoMaxRefinementDisplacement = "1.0"   []
Param: OdomFovis/StereoRequireMutualMatch = "true"         []
Param: OdomFovis/TargetPixelsPerFeature = "250"            [Specifies the desired feature density as a ratio of input image pixels per feature detected.  This number is used to control the adaptive feature thresholding.]
Param: OdomFovis/UpdateTargetFeaturesWithRefined = "false" [When subpixel refinement is enabled, the refined feature locations can be saved over the original feature locations.  This has a slightly negative impact on frame-to-frame visual odometry, but is likely better when using this library as part of a visual SLAM algorithm.]
Param: OdomFovis/UseAdaptiveThreshold = "true"             [Use FAST adaptive threshold.]
Param: OdomFovis/UseBucketing = "true"                     []
Param: OdomFovis/UseHomographyInitialization = "true"      [Use homography initialization.]
Param: OdomFovis/UseImageNormalization = "false"           []
Param: OdomFovis/UseSubpixelRefinement = "true"            [Specifies whether or not to refine feature matches to subpixel resolution.]
Param: OdomMono/InitMinFlow = "100"                        [Minimum optical flow required for the initialization step.]
Param: OdomMono/InitMinTranslation = "0.1"                 [Minimum translation required for the initialization step.]
Param: OdomMono/MaxVariance = "0.01"                       [Maximum variance to add new points to local map.]
Param: OdomMono/MinTranslation = "0.02"                    [Minimum translation to add new points to local map. On initialization, translation x 5 is used as the minimum.]
Param: OdomORBSLAM2/Bf = "0.076"                           [Fake IR projector baseline (m) used only when stereo is not used.]
Param: OdomORBSLAM2/ThDepth = "40.0"                       [Close/Far threshold. Baseline times.]
Param: OdomORBSLAM2/VocPath = ""                           [Path to ORB vocabulary (*.txt).]
Param: OdomViso2/BucketHeight = "50"                       [Height of bucket.]
Param: OdomViso2/BucketMaxFeatures = "2"                   [Maximal number of features per bucket.]
Param: OdomViso2/BucketWidth = "50"                        [Width of bucket.]
Param: OdomViso2/InlierThreshold = "2.0"                   [Fundamental matrix inlier threshold.]
Param: OdomViso2/MatchBinsize = "50"                       [Matching bin width/height (affects efficiency only).]
Param: OdomViso2/MatchDispTolerance = "2"                  [Disparity tolerance for stereo matches (in pixels).]
Param: OdomViso2/MatchHalfResolution = "true"              [Match at half resolution, refine at full resolution.]
Param: OdomViso2/MatchMultiStage = "true"                  [Multistage matching (denser and faster).]
Param: OdomViso2/MatchNmsN = "3"                           [Non-max-suppression: min. distance between maxima (in pixels).]
Param: OdomViso2/MatchNmsTau = "50"                        [Non-max-suppression: interest point peakiness threshold.]
Param: OdomViso2/MatchOutlierDispTolerance = "5"           [Outlier removal: disparity tolerance (in pixels).]
Param: OdomViso2/MatchOutlierFlowTolerance = "5"           [Outlier removal: flow tolerance (in pixels).]
Param: OdomViso2/MatchRadius = "200"                       [Matching radius (du/dv in pixels).]
Param: OdomViso2/MatchRefinement = "1"                     [Refinement (0=none,1=pixel,2=subpixel).]
Param: OdomViso2/RansacIters = "200"                       [Number of RANSAC iterations.]
Param: OdomViso2/Reweighting = "true"                      [Lower border weights (more robust to calibration errors).]
Param: Reg/Force3DoF = "false"                             [Force 3 degrees-of-freedom transform (3Dof: x,y and yaw). Parameters z, roll and pitch will be set to 0.]
Param: Reg/Strategy = "0"                                  [0=Vis, 1=Icp, 2=VisIcp]
Param: Reg/VarianceFromInliersCount = "false"              [Set variance as the inverse of the number of inliers. Otherwise, the variance is computed as the average 3D position error of the inliers.]
Param: Reg/VarianceNormalized = "false"                    [Normalize covariance values. Position variances are multiplied by norm of the transform and orientation variances are multiplied by angle of the transform.]
Param: SIFT/ContrastThreshold = "0.04"                     [The contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the less features are produced by the detector.]
Param: SIFT/EdgeThreshold = "10"                           [The threshold used to filter out edge-like features. Note that the its meaning is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are filtered out (more features are retained).]
Param: SIFT/NFeatures = "0"                                [The number of best features to retain. The features are ranked by their scores (measured in SIFT algorithm as the local contrast).]
Param: SIFT/NOctaveLayers = "3"                            [The number of layers in each octave. 3 is the value used in D. Lowe paper. The number of octaves is computed automatically from the image resolution.]
Param: SIFT/Sigma = "1.6"                                  [The sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft lenses, you might want to reduce the number.]
Param: SURF/Extended = "false"                             [Extended descriptor flag (true - use extended 128-element descriptors; false - use 64-element descriptors).]
Param: SURF/GpuKeypointsRatio = "0.01"                     [Used with SURF GPU.]
Param: SURF/GpuVersion = "false"                           [GPU-SURF: Use GPU version of SURF. This option is enabled only if OpenCV is built with CUDA and GPUs are detected.]
Param: SURF/HessianThreshold = "500"                       [Threshold for hessian keypoint detector used in SURF.]
Param: SURF/OctaveLayers = "2"                             [Number of octave layers within each octave.]
Param: SURF/Octaves = "4"                                  [Number of pyramid octaves the keypoint detector will use.]
Param: SURF/Upright = "false"                              [Up-right or rotated features flag (true - do not compute orientation of features; false - compute orientation).]
Param: Vis/BundleAdjustment = "0"                          [Optimization with bundle adjustment: 0=disabled, 1=g2o, 2=cvsba.]
Param: Vis/CorFlowEps = "0.01"                             [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorFlowIterations = "30"                        [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorFlowMaxLevel = "3"                           [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorFlowWinSize = "16"                           [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorGuessWinSize = "20"                          [[Vis/CorType=0] Matching window size (pixels) around projected points when a guess transform is provided to find correspondences. 0 means disabled.]
Param: Vis/CorNNDR = "0.6"                                 [[Vis/CorType=0] NNDR: nearest neighbor distance ratio. Used for features matching approach.]
Param: Vis/CorNNType = "1"                                 [[Vis/CorType=0] kNNFlannNaive=0, kNNFlannKdTree=1, kNNFlannLSH=2, kNNBruteForce=3, kNNBruteForceGPU=4. Used for features matching approach.]
Param: Vis/CorType = "0"                                   [Correspondences computation approach: 0=Features Matching, 1=Optical Flow]
Param: Vis/EpipolarGeometryVar = "0.02"                    [[Vis/EstimationType = 2] Epipolar geometry maximum variance to accept the transformation.]
Param: Vis/EstimationType = "1"                            [Motion estimation approach: 0:3D->3D, 1:3D->2D (PnP), 2:2D->2D (Epipolar Geometry)]
Param: Vis/FeatureType = "6"                               [0=SURF 1=SIFT 2=ORB 3=FAST/FREAK 4=FAST/BRIEF 5=GFTT/FREAK 6=GFTT/BRIEF 7=BRISK 8=GFTT/ORB 9=KAZE.]
Param: Vis/ForwardEstOnly = "true"                         [Forward estimation only (A->B). If false, a transformation is also computed in backward direction (B->A), then the two resulting transforms are merged (middle interpolation between the transforms).]
Param: Vis/InlierDistance = "0.1"                          [[Vis/EstimationType = 0] Maximum distance for feature correspondences. Used by 3D->3D estimation approach.]
Param: Vis/Iterations = "100"                              [Maximum iterations to compute the transform.]
Param: Vis/MaxDepth = "0"                                  [Max depth of the features (0 means no limit).]
Param: Vis/MaxFeatures = "1000"                            [0 no limits.]
Param: Vis/MinDepth = "0"                                  [Min depth of the features (0 means no limit).]
Param: Vis/MinInliers = "20"                               [Minimum feature correspondences to compute/accept the transformation.]
Param: Vis/PnPFlags = "0"                                  [[Vis/EstimationType = 1] PnP flags: 0=Iterative, 1=EPNP, 2=P3P]
Param: Vis/PnPRefineIterations = "1"                       [[Vis/EstimationType = 1] Refine iterations.]
Param: Vis/PnPReprojError = "2"                            [[Vis/EstimationType = 1] PnP reprojection error.]
Param: Vis/RefineIterations = "5"                          [[Vis/EstimationType = 0] Number of iterations used to refine the transformation found by RANSAC. 0 means that the transformation is not refined.]
Param: Vis/RoiRatios = "0.0 0.0 0.0 0.0"                   [Region of interest ratios [left, right, top, bottom].]
Param: Vis/SubPixEps = "0.02"                              [See cv::cornerSubPix().]
Param: Vis/SubPixIterations = "0"                          [See cv::cornerSubPix(). 0 disables sub pixel refining.]
Param: Vis/SubPixWinSize = "3"                             [See cv::cornerSubPix().]

